{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# l'objectif de ce notebook est de partager le dataset en sous groupe pour chaque compagnie d'aviation\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy as sc \n",
    "import matplotlib.pyplot as plt \n",
    "from itertools import product\n",
    "from sklearn import linear_model\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as gobj\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium \n",
    "import branca.colormap as cm\n",
    "from geopy.geocoders import Nominatim\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Représentations spatiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a pour objectif de réprésenter spatialement le retard et de définir quatres nouvelles variables la latitude et la longitude de l'aéroport de départ et d'arrivée. On visualise sur une carte géographique pour l'ensemble des compagnies, ainsi que pour chaque compagnie aérienne, le retard en fonction de l'aeroport. On visualise ensuite l'ensemble des liaisons pour l'ensemble des compagnies et pour chaqu'une des compagnies. \n",
    "On tient aussi compte graphiquement du traffic par aéroport et par trajet. \n",
    "Pour obtenir les données spatiales, on utilise un géo-encoder.\n",
    "Les cartes sont sauvegardés en fichiers html pour être implantées dans l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données brutes \n",
    "fly_data = pd.read_csv('datafly_tot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5635754, 10)\n",
      "Index(['Unnamed: 0', 'FL_DATE', 'ORIGIN_CITY_NAME', 'DEST_CITY_NAME',\n",
      "       'DEP_DELAY_NEW', 'ARR_DELAY_NEW', 'CANCELLED', 'DIVERTED', 'CARRIER',\n",
      "       'TAIL_NUM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (fly_data.shape)\n",
    "print (fly_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly_data = shuffle(fly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1127151, 10)\n"
     ]
    }
   ],
   "source": [
    "# réduire le nombre d'exemple pour encoder plus facilement \n",
    "m = fly_data.shape[0]\n",
    "fly_data = fly_data.iloc[0:int(np.around(m/5)),:]\n",
    "print (fly_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# détermine le nombre, les occurences / les pourcentages des objets pour une variable donnée\n",
    "def plot_value_counts2(col_name,n_oc):\n",
    "    \n",
    "    #we don't want more than 31 bars\n",
    "    if len(pd.DataFrame(df[col_name].dropna().value_counts())) > n_oc:\n",
    "        max = n_oc\n",
    "    else:\n",
    "        max = len(pd.DataFrame(df[col_name].dropna().value_counts()))\n",
    "        \n",
    "        \n",
    "    values_count = pd.DataFrame(df[col_name].dropna().value_counts()[:max])\n",
    "    values_count.columns = ['count']\n",
    "    # convert the index column into a regular column.\n",
    "    values_count[col_name] = [ str(i) for i in values_count.index ]\n",
    "    # add a column with the percentage of each data point to the sum of all data points.\n",
    "    values_count['percent'] = values_count['count'].div(values_count['count'].sum()).multiply(100).round(2)\n",
    "    # change the order of the columns.\n",
    "    values_count = values_count.reindex([col_name,'count','percent'],axis=1)\n",
    "    values_count.reset_index(drop=True,inplace=True)\n",
    "    return (values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CARRIER   count  percent\n",
      "0       WN  259463    23.02\n",
      "1       DL  194492    17.26\n",
      "2       AA  176822    15.69\n",
      "3       OO  121042    10.74\n",
      "4       UA  109118     9.68\n",
      "5       EV  100567     8.92\n",
      "6       B6   56819     5.04\n",
      "7       AS   33319     2.96\n",
      "8       NK   27730     2.46\n",
      "9       F9   19092     1.69\n",
      "10      HA   15294     1.36\n",
      "11      VX   13393     1.19\n"
     ]
    }
   ],
   "source": [
    "# on applique aux compagnies aeriennes :\n",
    "df = fly_data\n",
    "carrier = plot_value_counts2('CARRIER',n_oc=1000)\n",
    "print (carrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259463, 10)\n",
      "(194492, 10)\n",
      "(176822, 10)\n",
      "(121042, 10)\n",
      "(109118, 10)\n",
      "(100567, 10)\n",
      "(56819, 10)\n",
      "(33319, 10)\n",
      "(27730, 10)\n",
      "(19092, 10)\n",
      "(15294, 10)\n",
      "(13393, 10)\n"
     ]
    }
   ],
   "source": [
    "# pour chaque companie, on enregistre le dataframe en sous groupe :\n",
    "# liste des noms des companies /\n",
    "liste_name = []\n",
    "for i in range (carrier.shape[0]):\n",
    "    liste_name.append(carrier.iloc[i,0])\n",
    "\n",
    "for i in range (carrier.shape[0]):\n",
    "    carrier_unique = fly_data[fly_data['CARRIER'] == carrier.iloc[i,0]]\n",
    "    print (carrier_unique.shape) \n",
    "    # créer un dataframe pour chaque companie\n",
    "    liste_name[i] = carrier_unique\n",
    "    # sauvegarder en csv la nouvelle base de donnée\n",
    "    #index_month = carrier_unique.columns.get_loc('MONTH')   \n",
    "    #month = carrier_unique.iloc[0,index_month]\n",
    "    #carrier_val = carrier.iloc[i,0]    \n",
    "    #carrier_unique.to_csv(\"fd_{}_{}.csv\".format(month, carrier_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On étudie le retard en fonction du noms des villes, de l'importance du trajet/ la distancepour cela on visualise spacialement sur une carte les retards pour obtenir une idée des correlations entre ces différentes variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ORIGIN_CITY_NAME  count  percent\n",
      "0                Atlanta, GA  79108     7.02\n",
      "1                Chicago, IL  66576     5.91\n",
      "2                 Denver, CO  45145     4.01\n",
      "3            Los Angeles, CA  42611     3.78\n",
      "4      Dallas/Fort Worth, TX  39589     3.51\n",
      "5               New York, NY  39101     3.47\n",
      "6                Houston, TX  38623     3.43\n",
      "7          San Francisco, CA  34357     3.05\n",
      "8                Phoenix, AZ  31385     2.78\n",
      "9              Las Vegas, NV  29981     2.66\n",
      "10           Minneapolis, MN  26479     2.35\n",
      "11               Seattle, WA  26007     2.31\n",
      "12               Detroit, MI  25274     2.24\n",
      "13               Orlando, FL  25131     2.23\n",
      "14                Boston, MA  23977     2.13\n",
      "15                Newark, NJ  23408     2.08\n",
      "16        Salt Lake City, UT  22265     1.98\n",
      "17            Washington, DC  22009     1.95\n",
      "18             Charlotte, NC  20706     1.84\n",
      "19             Baltimore, MD  19329     1.71\n",
      "20       Fort Lauderdale, FL  17018     1.51\n",
      "21             San Diego, CA  15485     1.37\n",
      "22                 Miami, FL  14046     1.25\n",
      "23          Philadelphia, PA  13986     1.24\n",
      "24                Dallas, TX  13770     1.22\n",
      "25                 Tampa, FL  13537     1.20\n",
      "26              Portland, OR  11675     1.04\n",
      "27             St. Louis, MO  11161     0.99\n",
      "28             Nashville, TN  10334     0.92\n",
      "29               Oakland, CA   9815     0.87\n",
      "..                       ...    ...      ...\n",
      "277  International Falls, MN    114     0.01\n",
      "278          Santa Maria, CA    111     0.01\n",
      "279               Kodiak, AK    108     0.01\n",
      "280               Joplin, MO    100     0.01\n",
      "281             Longview, TX     92     0.01\n",
      "282           Bellingham, WA     92     0.01\n",
      "283        Niagara Falls, NY     90     0.01\n",
      "284                Tyler, TX     90     0.01\n",
      "285          Plattsburgh, NY     85     0.01\n",
      "286          Garden City, KS     76     0.01\n",
      "287                 Guam, TT     74     0.01\n",
      "288  North Bend/Coos Bay, OR     70     0.01\n",
      "289              Roswell, NM     68     0.01\n",
      "290         Grand Island, NE     58     0.01\n",
      "291    Martha's Vineyard, MA     57     0.01\n",
      "292             Gunnison, CO     41     0.00\n",
      "293     West Yellowstone, MT     38     0.00\n",
      "294        St. Augustine, FL     38     0.00\n",
      "295          Adak Island, AK     31     0.00\n",
      "296              Hyannis, MA     28     0.00\n",
      "297              Abilene, TX     24     0.00\n",
      "298             Gustavus, AK     22     0.00\n",
      "299            Pago Pago, TT     22     0.00\n",
      "300          Punta Gorda, FL     18     0.00\n",
      "301           Dillingham, AK     16     0.00\n",
      "302          King Salmon, AK     15     0.00\n",
      "303        Mammoth Lakes, CA     14     0.00\n",
      "304                     1829      1     0.00\n",
      "305             Wendover, UT      1     0.00\n",
      "306  Manhattan/Ft. Riley, KS      1     0.00\n",
      "\n",
      "[307 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# chercher le nom des villes ainsi que l'importance de chaque ville \n",
    "df = fly_data\n",
    "city = plot_value_counts2('ORIGIN_CITY_NAME',n_oc=1000)\n",
    "print (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ORIGIN_CITY_NAME  count  percent   latitude   longitude\n",
      "0                Atlanta, GA  79108     7.02  33.749099  -84.390185\n",
      "1                Chicago, IL  66576     5.91  41.875562  -87.624421\n",
      "2                 Denver, CO  45145     4.01  39.739143 -104.984696\n",
      "3            Los Angeles, CA  42611     3.78  34.053683 -118.242767\n",
      "4      Dallas/Fort Worth, TX  39589     3.51  32.760292  -97.161647\n",
      "5               New York, NY  39101     3.47  40.730862  -73.987156\n",
      "6                Houston, TX  38623     3.43  29.758938  -95.367697\n",
      "7          San Francisco, CA  34357     3.05  45.414978  -72.749396\n",
      "8                Phoenix, AZ  31385     2.78  33.448587 -112.077346\n",
      "9              Las Vegas, NV  29981     2.66  36.166286 -115.149225\n",
      "10           Minneapolis, MN  26479     2.35  44.977300  -93.265469\n",
      "11               Seattle, WA  26007     2.31  47.603832 -122.330062\n",
      "12               Detroit, MI  25274     2.24  42.331551  -83.046640\n",
      "13               Orlando, FL  25131     2.23  28.542110  -81.379039\n",
      "14                Boston, MA  23977     2.13  42.360253  -71.058291\n",
      "15                Newark, NJ  23408     2.08  40.735657  -74.172367\n",
      "16        Salt Lake City, UT  22265     1.98  40.767013 -111.890431\n",
      "17            Washington, DC  22009     1.95  38.895009  -77.036563\n",
      "18             Charlotte, NC  20706     1.84  35.227087  -80.843127\n",
      "19             Baltimore, MD  19329     1.71  39.290882  -76.610759\n",
      "20       Fort Lauderdale, FL  17018     1.51  26.122308  -80.143379\n",
      "21             San Diego, CA  15485     1.37  32.717421 -117.162771\n",
      "22                 Miami, FL  14046     1.25  25.774266  -80.193659\n",
      "23          Philadelphia, PA  13986     1.24  39.952415  -75.163575\n",
      "24                Dallas, TX  13770     1.22  32.776272  -96.796856\n",
      "25                 Tampa, FL  13537     1.20  27.947760  -82.458444\n",
      "26              Portland, OR  11675     1.04  45.520247 -122.674195\n",
      "27             St. Louis, MO  11161     0.99  38.627273  -90.197889\n",
      "28             Nashville, TN  10334     0.92  36.162230  -86.774353\n",
      "29               Oakland, CA   9815     0.87  44.456356  -64.357535\n",
      "..                       ...    ...      ...        ...         ...\n",
      "277  International Falls, MN    114     0.01  48.601049  -93.410982\n",
      "278          Santa Maria, CA    111     0.01  34.953130 -120.435858\n",
      "279               Kodiak, AK    108     0.01  57.790000 -152.407222\n",
      "280               Joplin, MO    100     0.01  37.084227  -94.513281\n",
      "281             Longview, TX     92     0.01  32.500704  -94.740489\n",
      "282           Bellingham, WA     92     0.01  48.754401 -122.478836\n",
      "283        Niagara Falls, NY     90     0.01  43.103093  -79.030262\n",
      "284                Tyler, TX     90     0.01  32.351260  -95.301062\n",
      "285          Plattsburgh, NY     85     0.01  44.692820  -73.455620\n",
      "286          Garden City, KS     76     0.01  37.971690 -100.872662\n",
      "287                 Guam, TT     74     0.01   0.000000    0.000000\n",
      "288  North Bend/Coos Bay, OR     70     0.01  43.406505 -124.224273\n",
      "289              Roswell, NM     68     0.01  33.394328 -104.522952\n",
      "290         Grand Island, NE     58     0.01  40.924271  -98.338685\n",
      "291    Martha's Vineyard, MA     57     0.01  39.074931  -94.417070\n",
      "292             Gunnison, CO     41     0.00  38.545825 -106.925321\n",
      "293     West Yellowstone, MT     38     0.00  44.664290 -111.105137\n",
      "294        St. Augustine, FL     38     0.00  29.894695  -81.314539\n",
      "295          Adak Island, AK     31     0.00  51.796165 -176.573492\n",
      "296              Hyannis, MA     28     0.00  41.651513  -70.282592\n",
      "297              Abilene, TX     24     0.00  32.446674  -99.733301\n",
      "298             Gustavus, AK     22     0.00  58.412838 -135.737565\n",
      "299            Pago Pago, TT     22     0.00  11.106782  125.005089\n",
      "300          Punta Gorda, FL     18     0.00  26.929784  -82.045366\n",
      "301           Dillingham, AK     16     0.00  59.901111 -158.201685\n",
      "302          King Salmon, AK     15     0.00  58.688434 -156.661838\n",
      "303        Mammoth Lakes, CA     14     0.00  37.626801 -118.846750\n",
      "304                     1829      1     0.00 -26.381172   27.843012\n",
      "305             Wendover, UT      1     0.00  40.737184 -114.037518\n",
      "306  Manhattan/Ft. Riley, KS      1     0.00   0.000000    0.000000\n",
      "\n",
      "[307 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# afficher les coordonnées correspondantes\n",
    "geolocator = Nominatim(user_agent='Tann',timeout=100) \n",
    "\n",
    "lat = np.zeros(city.shape[0]) # latitude correspondant à la ville\n",
    "long = np.zeros(city.shape[0]) # longitude correspondant à la ville\n",
    "ind = city.columns.get_loc('ORIGIN_CITY_NAME')\n",
    "liste = []\n",
    "\n",
    "for i in range (city.shape[0]):       \n",
    "    \n",
    "    location = geolocator.geocode(city.iloc[i,ind])\n",
    "    if location is None:\n",
    "        liste.append(i) \n",
    "        \n",
    "    elif location:    \n",
    "    \n",
    "        lat[i] = location.latitude\n",
    "        long[i] = location.longitude\n",
    "    \n",
    "city['latitude'] = lat[:]\n",
    "city['longitude'] = long[:]\n",
    "print (city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacramento, CA\n",
      "Mission/McAllen/Edinburg, TX\n",
      "Bristol/Johnson City/Kingsport, TN\n",
      "Saginaw/Bay City/Midland, MI\n",
      "Scranton/Wilkes-Barre, PA\n",
      "Jacksonville/Camp Lejeune, NC\n",
      "Sun Valley/Hailey/Ketchum, ID\n",
      "Iron Mountain/Kingsfd, MI\n",
      "Hattiesburg/Laurel, MS\n",
      "Newburgh/Poughkeepsie, NY\n",
      "New Bern/Morehead/Beaufort, NC\n",
      "Guam, TT\n",
      "Manhattan/Ft. Riley, KS\n"
     ]
    }
   ],
   "source": [
    "# ajouter les coordonnées manuellement \n",
    "for i in range (len(liste)):\n",
    "    print (city.iloc[liste[i],ind])\n",
    "ind_lat = city.columns.get_loc('latitude')\n",
    "ind_long = city.columns.get_loc('longitude')\n",
    "city.iloc[liste[0],ind_lat] = 38.684574\n",
    "city.iloc[liste[0],ind_long] = -121.588406\n",
    "\n",
    "city.iloc[liste[1],ind_lat] = 26.179868\n",
    "city.iloc[liste[1],ind_long] = -98.239391\n",
    "\n",
    "city.iloc[liste[2],ind_lat] = 43.536496\n",
    "city.iloc[liste[2],ind_long] = -84.080847\n",
    "\n",
    "city.iloc[liste[3],ind_lat] = 36.477382\n",
    "city.iloc[liste[3],ind_long] = -82.405566\n",
    "\n",
    "city.iloc[liste[4],ind_lat] = 41.338021\n",
    "city.iloc[liste[4],ind_long] = -75.728052\n",
    "\n",
    "city.iloc[liste[5],ind_lat] = 43.503787\n",
    "city.iloc[liste[5],ind_long] = -114.296088\n",
    "\n",
    "city.iloc[liste[6],ind_lat] = 34.712303\n",
    "city.iloc[liste[6],ind_long] =  -77.580538\n",
    "\n",
    "city.iloc[liste[7],ind_lat] =  41.507298\n",
    "city.iloc[liste[7],ind_long] = -74.103223\n",
    "\n",
    "city.iloc[liste[8],ind_lat] = 35.076250\n",
    "city.iloc[liste[8],ind_long] = -77.038637\n",
    "\n",
    "city.iloc[liste[9],ind_lat] = 45.814810\n",
    "city.iloc[liste[9],ind_long] =  -88.115630\n",
    "\n",
    "city.iloc[liste[10],ind_lat] = 31.665073\n",
    "city.iloc[liste[10],ind_long] = -89.170729\n",
    "\n",
    "city.iloc[liste[11],ind_lat] = 13.486790\n",
    "city.iloc[liste[11],ind_long] = 144.794289\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restreint les datasets aux variables villes et retard : \n",
    "liste_name_red = []\n",
    "\n",
    "fly_data_red = fly_data[['ORIGIN_CITY_NAME','DEST_CITY_NAME',\n",
    "                         'ARR_DELAY_NEW','DEP_DELAY_NEW']]\n",
    "for i in range (len(liste_name)):\n",
    "    liste_name_red.append(liste_name[i][['ORIGIN_CITY_NAME',\n",
    "                                             'DEST_CITY_NAME','ARR_DELAY_NEW','DEP_DELAY_NEW']])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1127151\n",
      "1110832\n",
      "1110821\n"
     ]
    }
   ],
   "source": [
    "# supprimer les retard de plus de 12h \n",
    "\n",
    "print (fly_data.shape[0])\n",
    "fly_data_red = fly_data_red[fly_data_red['ARR_DELAY_NEW']<= 720 ]\n",
    "print (fly_data_red.shape[0])\n",
    "fly_data_red = fly_data_red[fly_data_red['DEP_DELAY_NEW']<= 720 ]\n",
    "print (fly_data_red.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4098\n",
      "4098\n",
      "4098\n",
      "4098\n",
      "4098\n",
      "4098\n",
      "4098\n",
      "307\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "# on compte le nombre de liaisons ville de départ > ville d'arrivée \n",
    "# on enregistre les coordonnées de type lat_dep, long_dep lat_ar long_ar\n",
    "index_long = city.columns.get_loc('longitude')\n",
    "index_lat = city.columns.get_loc('latitude')\n",
    "\n",
    "# listes des coordonnées des villes de départ et d'arrivée\n",
    "lat_dep = []\n",
    "long_dep = []\n",
    "lat_arr = []\n",
    "long_arr = []\n",
    "\n",
    "# importance du trajet \n",
    "count_path = []\n",
    "\n",
    "# retards moyens par trajet\n",
    "delay_dep_path = []\n",
    "delay_arr_path = []\n",
    "\n",
    "# retards moyens par ville \n",
    "delay_dep_city = []\n",
    "delay_arr_city = []\n",
    "\n",
    "for i in range (city.shape[0]): \n",
    "        \n",
    "        # réduit le dataset à la ville considérée\n",
    "        city_red = fly_data_red[fly_data_red['ORIGIN_CITY_NAME'] == city.iloc[i,0]] \n",
    "        # enregistre le retard moyen par ville \n",
    "        delay_dep_city.append(city_red.iloc[:,3].sum(axis=0)/city.iloc[i,1])\n",
    "        delay_arr_city.append(city_red.iloc[:,2].sum(axis=0)/city.iloc[i,1])\n",
    "        #delay_dep_city.append(np.median(city_red.iloc[:,3]))        \n",
    "        #delay_arr_city.append(np.median(city_red.iloc[:,2]))\n",
    "        # compte le nombre de valeurs > importance de l'aeroport \n",
    "        num_liaison = city_red.shape[0]\n",
    "        # étudie les villes d'arrivée /\n",
    "        df = city_red        \n",
    "        city_ar = plot_value_counts2('DEST_CITY_NAME',n_oc=1000)\n",
    "        \n",
    "        for j in range (city_ar.shape[0]):\n",
    "            \n",
    "            # réduit le dataset au chemin (ville de départ > ville d'arrivée)\n",
    "            city_ar_red = city_red[city_red['DEST_CITY_NAME'] == city_ar.iloc[j,0]]\n",
    "            # enregistre le retard moyen par trajet\n",
    "            delay_dep_path.append(city_ar_red.iloc[:,3].sum(axis=0)/city_ar.iloc[j,1])\n",
    "            delay_arr_path.append(city_ar_red.iloc[:,2].sum(axis=0)/city_ar.iloc[j,1])\n",
    "            #delay_dep_path.append(np.median(city_ar_red.iloc[:,3]))\n",
    "            #delay_arr_path.append(np.median(city_ar_red.iloc[:,2]))\n",
    "            \n",
    "            city_ar_co = city[city['ORIGIN_CITY_NAME'] == city_ar.iloc[j,0]] \n",
    "            # coordonnées de la ville de départ \n",
    "            lat_dep.append(city.iloc[i,index_lat])\n",
    "            long_dep.append(city.iloc[i,index_long])\n",
    "            # coordonnée de la ville d'arrivée \n",
    "            lat_arr.append(city_ar_co.iloc[0,index_lat])\n",
    "            long_arr.append(city_ar_co.iloc[0,index_long])\n",
    "            # importance du trajet \n",
    "            count_path.append(city_ar.iloc[j,1])\n",
    "            \n",
    "print (len(lat_dep))\n",
    "print (len(long_dep))\n",
    "print (len(lat_arr))\n",
    "print (len(long_arr))\n",
    "print (len(count_path))\n",
    "\n",
    "print (len(delay_dep_path))\n",
    "print (len(delay_arr_path))\n",
    "\n",
    "print (len(delay_dep_city))\n",
    "print (len(delay_arr_city))      \n",
    "        \n",
    "        \n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.08701138 0.97739872 1.12522983\n",
      " 1.19748119 1.22287696 1.26322514 1.29928298 1.36022212 1.40310148\n",
      " 1.43694615 1.45125226 1.5260563  1.54817903 1.72509697 1.74527183\n",
      " 1.77328544 1.78072458 1.79303093 1.80874829 1.80915121 1.87271534\n",
      " 1.91192914 1.93753314 1.94113687 1.95990634 1.98403621 1.98591548\n",
      " 1.99837835 2.00875126 2.00978554 2.01438609 2.03343216 2.04122033\n",
      " 2.04352183 2.0483074  2.05579978 2.05891205 2.06056892 2.06216996\n",
      " 2.07060535 2.0747134  2.1005385  2.10241285 2.109798   2.11731803\n",
      " 2.13268606 2.147839   2.16177101 2.1630786  2.1690901  2.17770091\n",
      " 2.19722458 2.19794582 2.1981312  2.20047987 2.20054226 2.20399921\n",
      " 2.20565455 2.20873218 2.21063884 2.21200121 2.22217061 2.22714134\n",
      " 2.22757297 2.23035037 2.23489799 2.2349141  2.23671235 2.23994952\n",
      " 2.24349618 2.24440314 2.24513666 2.25622546 2.26096091 2.26600877\n",
      " 2.27052034 2.27423764 2.2791749  2.27962856 2.27965759 2.28096034\n",
      " 2.29025448 2.29347242 2.29563352 2.29820049 2.30234922 2.30258509\n",
      " 2.30371864 2.31078118 2.31228233 2.31763027 2.32505795 2.32688962\n",
      " 2.32753234 2.32758263 2.33183752 2.33481949 2.34094038 2.34624404\n",
      " 2.34770326 2.35090465 2.35423352 2.35601157 2.35696186 2.35891384\n",
      " 2.36277109 2.36320971 2.36457208 2.36985403 2.37275846 2.3728771\n",
      " 2.37520631 2.38449226 2.39176499 2.39296999 2.39459603 2.39501816\n",
      " 2.39648209 2.39881107 2.40305214 2.40391611 2.40505772 2.40772819\n",
      " 2.41164445 2.4137396  2.41456489 2.41509556 2.41660927 2.41666538\n",
      " 2.41718848 2.41888818 2.41959224 2.41973301 2.42077854 2.42257905\n",
      " 2.42359452 2.42554382 2.42667647 2.43256017 2.43300821 2.43347891\n",
      " 2.43401828 2.43423197 2.43809305 2.4382582  2.44037123 2.44519295\n",
      " 2.45005538 2.45388531 2.45960967 2.46298339 2.46701709 2.46900218\n",
      " 2.47909869 2.47927283 2.48052205 2.48073128 2.48436885 2.48441281\n",
      " 2.48930078 2.49053558 2.49219374 2.49535534 2.49586175 2.50048346\n",
      " 2.50107951 2.50463116 2.5065405  2.50709223 2.50783619 2.51064954\n",
      " 2.51255818 2.51260162 2.51270893 2.51366706 2.51423426 2.51430625\n",
      " 2.51934036 2.51962128 2.52855294 2.53222297 2.53525178 2.53526498\n",
      " 2.53552304 2.53703147 2.53794727 2.53884855 2.54118951 2.54489856\n",
      " 2.54633876 2.54681591 2.54687863 2.55498567 2.55715525 2.55773603\n",
      " 2.55810212 2.56039031 2.56224665 2.5660968  2.5669716  2.57059231\n",
      " 2.57096441 2.57412833 2.57505952 2.58013074 2.58159621 2.58341349\n",
      " 2.58461211 2.5850248  2.58719839 2.58927109 2.59045372 2.59934902\n",
      " 2.60268969 2.60355064 2.60472465 2.60747126 2.60750897 2.60899317\n",
      " 2.60935511 2.61331511 2.6146233  2.62210777 2.62337244 2.62442405\n",
      " 2.62522142 2.62843092 2.6291606  2.62961285 2.63645128 2.63824531\n",
      " 2.64204152 2.64231048 2.64393264 2.64606162 2.65710084 2.65786046\n",
      " 2.65826204 2.65970937 2.66670537 2.66779746 2.6700568  2.67185735\n",
      " 2.67199115 2.672266   2.67277418 2.67414865 2.67898607 2.68565438\n",
      " 2.68650791 2.69338379 2.69435314 2.69664842 2.70093632 2.70143705\n",
      " 2.70275568 2.71845342 2.71895321 2.72692528 2.73307239 2.73641247\n",
      " 2.74765291 2.75023182 2.75028296 2.75566551 2.75718959 2.76546111\n",
      " 2.76703355 2.77050861 2.77568978 2.78447257 2.78956007 2.79157283\n",
      " 2.79737735 2.79863075 2.80289342 2.81294657 2.81882811 2.82957284\n",
      " 2.83366228 2.84277136 2.84752277 2.8576794  2.85902123 2.87616193\n",
      " 2.89519104 2.89712398 2.90600688 2.91557695 2.93539278 2.96133444\n",
      " 2.97657766 3.016603   3.04656117 3.05604561 3.10209948 3.11625129\n",
      " 3.11913795 3.12947916 3.14299766 3.16547505 3.26501439 3.27216712\n",
      " 3.28497563]\n"
     ]
    }
   ],
   "source": [
    "# créer une liste couleur : \n",
    "couleurs = ['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "           '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333']\n",
    "\n",
    "delay_dep_path_c = []\n",
    "delay_arr_paty_c = []\n",
    "delay_dep_city_c = []\n",
    "delay_arr_city_c = []\n",
    "\n",
    "# associer une échelle log\n",
    "for i in range (len(delay_dep_path)):\n",
    "    \n",
    "    delay_dep_path[i] = np.log(delay_dep_path[i] + 1)\n",
    "    delay_arr_path[i] = np.log(delay_arr_path[i] + 1)\n",
    "for i in range (len(delay_dep_city)):\n",
    "    \n",
    "    delay_dep_city[i] = np.log(delay_dep_city[i] + 1)\n",
    "    delay_arr_city[i] = np.log(delay_arr_city[i] + 1)      \n",
    "\n",
    "\n",
    "delay_dep_path_c = (pd.cut((delay_dep_path[:]), \n",
    "             14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "delay_arr_path_c = (pd.cut((delay_arr_path[:]), \n",
    "             14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "delay_dep_city_c = (pd.cut(delay_dep_city[:], \n",
    "             14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "delay_arr_city_c = (pd.cut(delay_arr_city[:], \n",
    "             14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "\n",
    "# remplacer les lettres dans par les chiffres correspondants\n",
    "z = {'A': 0, 'B': 1, 'C': 2,'D':3 ,'E':4, 'F': 5, 'G': 6, 'H': 7,'I':8 ,'J':9,\n",
    "    'K': 10, 'L': 11, 'M': 12, 'N': 13}\n",
    "delay_dep_path_c = delay_dep_path_c.map(z)\n",
    "delay_arr_path_c = delay_arr_path_c.map(z)\n",
    "delay_dep_city_c = delay_dep_city_c.map(z)\n",
    "delay_arr_city_c = delay_arr_city_c.map(z)\n",
    "\n",
    "print (np.sort(delay_dep_city))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# établir une carte de visualisation des villes via leurs importances respectives et leurs retards\n",
    "index_long = city.columns.get_loc('longitude')\n",
    "index_lat = city.columns.get_loc('latitude')\n",
    "# Make an empty map\n",
    "m = folium.Map(location=[40,-100], tiles=\"CartoDB dark_matter\", zoom_start=3)\n",
    "\n",
    "colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "           '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "            vmin=0, vmax=np.amax(delay_dep_city))\n",
    "colormap.caption = 'Retard moyen au départ'\n",
    "m.add_child(colormap)\n",
    "\n",
    "m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "# I can add marker one by one on the map\n",
    "for i in range(city.shape[0]):\n",
    "    \n",
    "    folium.Circle(\n",
    "    location=[city.iloc[i,index_lat],city.iloc[i,index_long]],\n",
    "    radius=(int((np.log(city.iloc[i,1])*10000))),\n",
    "    color=couleurs[int(delay_dep_city_c[i])],\n",
    "    fill=True,\n",
    "    fill_color=couleurs[int(delay_dep_city_c[i])]).add_to(m)\n",
    " \n",
    "# Save it as html\n",
    "m.save('globalmap_airport.html')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# établir une carte de visualisation des villes via leurs importances respectives et leurs retards\n",
    "index_long = city.columns.get_loc('longitude')\n",
    "index_lat = city.columns.get_loc('latitude')\n",
    "# Make an empty map\n",
    "m = folium.Map(location=[20,0], tiles=\"CartoDB dark_matter\", zoom_start=2)\n",
    "\n",
    "colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "           '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "            vmin=0, vmax=np.amax(delay_dep_city))\n",
    "colormap.caption = 'Retard moyen a larrive'\n",
    "m.add_child(colormap)\n",
    "\n",
    "m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "# I can add marker one by one on the map\n",
    "for i in range(city.shape[0]):\n",
    "    \n",
    "    folium.Circle(\n",
    "    location=[city.iloc[i,index_lat],city.iloc[i,index_long]],\n",
    "    radius=(int((np.log(city.iloc[i,1])*10000))),\n",
    "    color=couleurs[int(delay_arr_city_c[i])],\n",
    "    fill=True,\n",
    "    fill_color=couleurs[int(delay_arr_city_c[i])]).add_to(m)\n",
    " \n",
    "# Save it as html\n",
    "m.save('mymap_delaycity_arr.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracer les trajets en fonction de l'importance et du retard \n",
    "#map = folium.Map(width=500,height=500,location=[40, -99], zoom_start=4)\n",
    "\n",
    "# Make an empty map\n",
    "m = folium.Map(location=[40,-100], tiles=\"CartoDB dark_matter\", zoom_start=3)\n",
    "\n",
    "colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "           '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "            vmin=0, vmax=np.amax(delay_dep_city))\n",
    "colormap.caption = 'Retard moyen au départ'\n",
    "m.add_child(colormap)\n",
    "\n",
    "m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "for i in range (len(count_path)):\n",
    "    folium.features.PolyLine(locations=[[lat_dep[i],long_dep[i]],\n",
    "                                [lat_arr[i],long_arr[i]]],                                          \n",
    "                                weight=0.15,\n",
    "                                color=couleurs[int(delay_arr_path_c[i])],\n",
    "                                popup=None).add_to(m)\n",
    "    \n",
    "# Save it as html\n",
    "m.save('global_mappath.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# même procédure en distinguant les companies d'aviation :\n",
    "\n",
    "# chercher le nom des villes ainsi que l'importance de chaque ville \n",
    "\n",
    "for k in range (len(liste_name_red)):\n",
    "    df = liste_name_red[k]\n",
    "    city_c = plot_value_counts2('ORIGIN_CITY_NAME',n_oc=1000)\n",
    "\n",
    "    # supprimer les retard de plus de 12h \n",
    "    fly_data_red = liste_name_red[k]\n",
    "    fly_data_red = fly_data_red[fly_data_red['ARR_DELAY_NEW']<= 720 ]\n",
    "    fly_data_red = fly_data_red[fly_data_red['DEP_DELAY_NEW']<= 720 ]\n",
    "\n",
    "    # on compte le nombre de liaisons ville de départ > ville d'arrivée \n",
    "    # on enregistre les coordonnées de type lat_dep, long_dep lat_ar long_ar\n",
    "    index_long = city.columns.get_loc('longitude')\n",
    "    index_lat = city.columns.get_loc('latitude')\n",
    "\n",
    "    # listes des coordonnées des villes de départ et d'arrivée\n",
    "    lat_dep = []\n",
    "    long_dep = []\n",
    "    lat_arr = []\n",
    "    long_arr = []\n",
    "\n",
    "    # importance du trajet \n",
    "    count_path = []\n",
    "\n",
    "    # retards moyens par trajet\n",
    "    delay_dep_path = []\n",
    "    delay_arr_path = []\n",
    "\n",
    "    # retards moyens par ville \n",
    "    delay_dep_city = []\n",
    "    delay_arr_city = []\n",
    "\n",
    "    for i in range (city_c.shape[0]): \n",
    "\n",
    "            # réduit le dataset à la ville considérée\n",
    "            city_red = fly_data_red[fly_data_red['ORIGIN_CITY_NAME'] == city_c.iloc[i,0]] \n",
    "            # enregistre le retard moyen par ville \n",
    "            delay_dep_city.append(city_red.iloc[:,3].sum(axis=0)/city_c.iloc[i,1])\n",
    "            delay_arr_city.append(city_red.iloc[:,2].sum(axis=0)/city_c.iloc[i,1])\n",
    "            #delay_dep_city.append(np.median(city_red.iloc[:,3]))        \n",
    "            #delay_arr_city.append(np.median(city_red.iloc[:,2]))\n",
    "            # compte le nombre de valeurs > importance de l'aeroport \n",
    "            num_liaison = city_red.shape[0]\n",
    "            # étudie les villes d'arrivée /\n",
    "            df = city_red        \n",
    "            city_ar = plot_value_counts2('DEST_CITY_NAME',n_oc=1000)\n",
    "\n",
    "            for j in range (city_ar.shape[0]):\n",
    "\n",
    "                # réduit le dataset au chemin (ville de départ > ville d'arrivée)\n",
    "                city_ar_red = city_red[city_red['DEST_CITY_NAME'] == city_ar.iloc[j,0]]\n",
    "                # enregistre le retard moyen par trajet\n",
    "                delay_dep_path.append(city_ar_red.iloc[:,3].sum(axis=0)/city_ar.iloc[j,1])\n",
    "                delay_arr_path.append(city_ar_red.iloc[:,2].sum(axis=0)/city_ar.iloc[j,1])\n",
    "                #delay_dep_path.append(np.median(city_ar_red.iloc[:,3]))\n",
    "                #delay_arr_path.append(np.median(city_ar_red.iloc[:,2]))\n",
    "\n",
    "                city_ar_co = city[city['ORIGIN_CITY_NAME'] == city_ar.iloc[j,0]] \n",
    "                city_dep_co = city[city['ORIGIN_CITY_NAME'] == city_c.iloc[i,0]] \n",
    "                # coordonnées de la ville de départ \n",
    "                lat_dep.append(city_dep_co.iloc[0,index_lat])\n",
    "                long_dep.append(city_dep_co.iloc[0,index_long])\n",
    "                # coordonnée de la ville d'arrivée \n",
    "                lat_arr.append(city_ar_co.iloc[0,index_lat])\n",
    "                long_arr.append(city_ar_co.iloc[0,index_long])\n",
    "                # importance du trajet \n",
    "                count_path.append(city_ar.iloc[j,1])\n",
    "\n",
    "    # créer une liste couleur : \n",
    "    couleurs = ['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "               '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333']\n",
    "\n",
    "    delay_dep_path_c = []\n",
    "    delay_arr_paty_c = []\n",
    "    delay_dep_city_c = []\n",
    "    delay_arr_city_c = []\n",
    "\n",
    "    # associer une échelle log\n",
    "    for i in range (len(delay_dep_path)):\n",
    "\n",
    "        delay_dep_path[i] = np.log(delay_dep_path[i] + 1)\n",
    "        delay_arr_path[i] = np.log(delay_arr_path[i] + 1)\n",
    "    for i in range (len(delay_dep_city)):\n",
    "\n",
    "        delay_dep_city[i] = np.log(delay_dep_city[i] + 1)\n",
    "        delay_arr_city[i] = np.log(delay_arr_city[i] + 1)      \n",
    "\n",
    "\n",
    "    delay_dep_path_c = (pd.cut((delay_dep_path[:]), \n",
    "                 14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "    delay_arr_path_c = (pd.cut((delay_arr_path[:]), \n",
    "                 14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "    delay_dep_city_c = (pd.cut(delay_dep_city[:], \n",
    "                 14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "    delay_arr_city_c = (pd.cut(delay_arr_city[:], \n",
    "                 14, labels=['A','B','C','D','E','F','G','H','I','J','K','L','M','N']))\n",
    "\n",
    "    # remplacer les lettres dans par les chiffres correspondants\n",
    "    z = {'A': 0, 'B': 1, 'C': 2,'D':3 ,'E':4, 'F': 5, 'G': 6, 'H': 7,'I':8 ,'J':9,\n",
    "        'K': 10, 'L': 11, 'M': 12, 'N': 13}\n",
    "    delay_dep_path_c = delay_dep_path_c.map(z)\n",
    "    delay_arr_path_c = delay_arr_path_c.map(z)\n",
    "    delay_dep_city_c = delay_dep_city_c.map(z)\n",
    "    delay_arr_city_c = delay_arr_city_c.map(z)\n",
    "\n",
    "\n",
    "    # établir une carte de visualisation des villes via leurs importances respectives et leurs retards\n",
    "    index_long = city.columns.get_loc('longitude')\n",
    "    index_lat = city.columns.get_loc('latitude')\n",
    "    # Make an empty map\n",
    "    m = folium.Map(location=[40,-100], tiles=\"CartoDB dark_matter\", zoom_start=3)\n",
    "\n",
    "    colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "               '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "                vmin=0, vmax=np.amax(delay_dep_city))\n",
    "    colormap.caption = 'Retard moyen au départ'\n",
    "    m.add_child(colormap)\n",
    "\n",
    "    m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "    # I can add marker one by one on the map\n",
    "    for i in range(city_c.shape[0]):\n",
    "        \n",
    "        \n",
    "        \n",
    "        city_dep_co = city[city['ORIGIN_CITY_NAME'] == city_c.iloc[i,0]] \n",
    "        \n",
    "        folium.Circle(\n",
    "        location=[city_dep_co.iloc[0,index_lat],city_dep_co.iloc[0,index_long]],\n",
    "        radius=(int((np.log(city_c.iloc[i,1])*10000))),\n",
    "        color=couleurs[int(delay_dep_city_c[i])],\n",
    "        fill=True,\n",
    "        fill_color=couleurs[int(delay_dep_city_c[i])]).add_to(m)\n",
    "\n",
    "    # Save it as html\n",
    "    m.save('map_carrierairport{}.html'.format(k))\n",
    "\n",
    "\n",
    "    # établir une carte de visualisation des villes via leurs importances respectives et leurs retards\n",
    "    index_long = city.columns.get_loc('longitude')\n",
    "    index_lat = city.columns.get_loc('latitude')\n",
    "    # Make an empty map\n",
    "    m = folium.Map(location=[40,-100], tiles=\"CartoDB dark_matter\", zoom_start=3)\n",
    "\n",
    "    colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "               '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "                vmin=0, vmax=np.amax(delay_dep_city))\n",
    "    colormap.caption = 'Retard moyen a larrive'\n",
    "    m.add_child(colormap)\n",
    "\n",
    "    m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "    # I can add marker one by one on the map\n",
    "    for i in range(city_c.shape[0]):\n",
    "        \n",
    "        city_dep_co = city[city['ORIGIN_CITY_NAME'] == city_c.iloc[i,0]] \n",
    "\n",
    "        folium.Circle(\n",
    "        location=[city_dep_co.iloc[0,index_lat],city_dep_co.iloc[0,index_long]],\n",
    "        radius=(int((np.log(city_c.iloc[i,1])*10000))),\n",
    "        color=couleurs[int(delay_arr_city_c[i])],\n",
    "        fill=True,\n",
    "        fill_color=couleurs[int(delay_arr_city_c[i])]).add_to(m)\n",
    "\n",
    "    # Save it as html\n",
    "    m.save('mymap_delaycity_arr{}.html'.format(k))\n",
    "\n",
    "    # tracer les trajets en fonction de l'importance et du retard \n",
    "\n",
    "\n",
    "    # Make an empty map\n",
    "    m = folium.Map(location=[40,-100], tiles=\"CartoDB dark_matter\", zoom_start=3)\n",
    "\n",
    "    colormap = cm.StepColormap(['#33ff66','#33ff99','#33ffcc','#33ffff','#33ccff','#3399ff','#3366ff','#3333ff','#6633ff','#9933ff','#cc33ff',\n",
    "               '#ff33ff','#ff33cc','#ff3399','#ff3366','#ff3333'],\n",
    "                vmin=0, vmax=np.amax(delay_dep_city))\n",
    "    colormap.caption = 'Retard moyen au départ'\n",
    "    m.add_child(colormap)\n",
    "\n",
    "    m.save('results', 'Colormaps_3.html')\n",
    "\n",
    "    for i in range (len(count_path)):\n",
    "        folium.features.PolyLine(locations=[[lat_dep[i],long_dep[i]],\n",
    "                                    [lat_arr[i],long_arr[i]]],                                          \n",
    "                                    weight=0.15,\n",
    "                                    color=couleurs[int(delay_arr_path_c[i])],\n",
    "                                    popup=None).add_to(m)\n",
    "\n",
    "    # Save it as html\n",
    "    m.save('map_carrierpath{}.html'.format(k))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
